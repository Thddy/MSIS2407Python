{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9895ce",
   "metadata": {},
   "source": [
    "# HW 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a0025",
   "metadata": {},
   "source": [
    "## By: Jacob Thaddeus Holmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3907b",
   "metadata": {},
   "source": [
    "### The goal of this program is to do a sentiment analysis based on a text file which contains numerous tweets in its raw text format. Code is written to use any user inputed text file name that is in the same folder as the code file. All demonstrated results collected in this file contain a keyword specified by me, the student. I tested Biden.txt, Putin.txt, UN.txt, and the provided Trump_Raw_Tweets_Fall22.txt. The Biden, Putin, and UN files were created using the provided tweetering function with my own token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37beec7",
   "metadata": {},
   "source": [
    "this cell makes sure that all of the outputs of a cell are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b2b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29f603",
   "metadata": {},
   "source": [
    "this cell disables autosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675d8082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118c493",
   "metadata": {},
   "source": [
    "The below cell defines the readclean function which is referenced in a following function. It takes the given text file name, reads the files as strings and closes the tweet file as well as reference word files, then strips all the referenced files of punctuation, converts them to lists, and finally stores all of the data in a dictinoary to be referenced by the process function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b87ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readclean(file):\n",
    "    #initializes punctuation variable for data cleaning\n",
    "    pun = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    #initializes result dictionary for use\n",
    "    result= {}\n",
    "    #reads each file to specified variables as string, then closed due to the nature of the with function, I googled this.\n",
    "    with open(file,'r') as f:\n",
    "        t=f.read()\n",
    "    with open('negative.txt', 'r') as f:\n",
    "        n=f.read()\n",
    "    with open('positive.txt', 'r') as f:\n",
    "        p=f.read()\n",
    "    with open('stop.txt', 'r') as f:\n",
    "        s=f.read()\n",
    "    #strips tweet file of punctuation .rstrip wasn't removing all of the punctuation for some reason\n",
    "    tc = ''\n",
    "    for i in t:\n",
    "        if i not in pun:\n",
    "            tc = tc + i\n",
    "    #cleans all of the files, throws in an extra rstrip for good measure, and converts each item to list, stores in dictionary\n",
    "    result['tweets'] = tc.rstrip(pun).lower().split()\n",
    "    result['neg'] = n.rstrip(pun).lower().split()\n",
    "    result['pos'] = p.rstrip(pun).lower().split()\n",
    "    result['stop'] = s.rstrip(pun).lower().split()\n",
    "    #If statement to remove trump from positive word list if Trump is in the file name\n",
    "    if 'Trump' in file or \"trump\" in file:\n",
    "        result['pos'].remove(\"trump\")\n",
    "    else:\n",
    "        pass \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5268a",
   "metadata": {},
   "source": [
    "The below cell defines the process function which takes a dictionary with standardized keys from the readclean function and utilizes for loops to sum all of the negative, positive, stop, and other words in the cleaned tweet file. It stores this data in a new dictionary to be used in the analyze function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39f44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file):\n",
    "    # initializes count for total, negative, positive, stop, and initializes a dictonary 'r' to store the results\n",
    "    r = {'total':0,'negative':0,'positive':0,'stop':0,'other':0}\n",
    "    r['total']=len(file['tweets'])\n",
    "    #loops through every tweeted word and counts each negative, positive, stop, and other word\n",
    "    for i in file['tweets']:\n",
    "        if i in file['neg']:\n",
    "            r['negative']=r['negative']+1\n",
    "        elif i in file['pos']:\n",
    "            r['positive']=r['positive']+1\n",
    "        elif i in file['stop']:\n",
    "            r['stop']=r['stop']+1\n",
    "        else:\n",
    "            r['other']=r['other']+1\n",
    "    return r\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd2e44",
   "metadata": {},
   "source": [
    "The below cell defines the analyze function which takes the dictionary returned by the process function and addresses the questions in the homework. I included some fun time and text formating to make the output come out in a more \"computer like\" way that the user can enjoy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baeb04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(file):\n",
    "    #imports the time commands to add some fun timing to the output\n",
    "    import time\n",
    "    #defines BOLD END under end variables that I used to add bold and underline to some of the output, saving as variables\n",
    "    #made for more efficient coding as I wasn't going to remember the codes. I found built-in ANSI escape sequences online.\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    under = '\\x1b[4m'\n",
    "    end = '\\x1B[0m'\n",
    "    print (BOLD + under + 'Analysis Results:'+ end + END)\n",
    "    time.sleep(0.25)\n",
    "    print (BOLD + 'Question 1:' + END)\n",
    "    #for loop to print out all of the different word counts established in the process function\n",
    "    for key in file:\n",
    "        print ('the ' + str(key) +\" word count is \" +str(file[key]))\n",
    "        time.sleep(0.25)\n",
    "    print(BOLD + 'Question 2:' + END)\n",
    "    time.sleep(0.25)\n",
    "    #for loop that prints out the ratios of various word counts to the total word count, rounded for ease\n",
    "    for key in file:\n",
    "        print ('the ' + str(key) +\" word ratio is: \" +str(round(file[key]/file['total'],2))+\":1\")\n",
    "        time.sleep(0.25)\n",
    "    print(BOLD + 'Question 3:'+ END)\n",
    "    time.sleep(0.25)\n",
    "    #initializes a ratio variable that is the ratio of positive to negative words, rounded for ease\n",
    "    ratio = round(file['positive']/file['negative'],2)\n",
    "    #prints the ratio in an easy to understand manner\n",
    "    print ('the ratio of positive words to negative words is ' + str(ratio) +\":1\")\n",
    "    time.sleep(0.25)\n",
    "    print(BOLD + 'Question 4:' + END)\n",
    "    #Uses if/elif/else to rate this positive/negative ratio as strongly positive, to strongly negative, not quite sure if\n",
    "    #these strong/weak numbers I used are correct, can be easily modified\n",
    "    time.sleep(0.25)\n",
    "    if ratio > 1.2:\n",
    "        print(\" the sentiment is strongly positive\")\n",
    "    elif 1.0 < ratio <= 1.2:\n",
    "        print(\"the sentiment is weakly positive\")\n",
    "    elif ratio == 1.0:\n",
    "        print(\"the sentiment is neutral\")\n",
    "    elif 0.8< ratio < 1.0:\n",
    "        print (\"the sentiment is weakly negative\")\n",
    "    else:\n",
    "        print (\"the sentiment is strongly negative\")\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e3e9e",
   "metadata": {},
   "source": [
    "The below cell defines the HW1 function which takes the three above functions and combines them into one for user ease. It requests that the user input the file name and then runs all of the functions and includes some fun time and formatting to make it clear to the user what the program is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8d4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HW1():\n",
    "    #imports the time command for some fun\n",
    "    import time\n",
    "    #initiates BOLD and END variables to be used for ease of coding BOLD text into my print outputs\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    #Asks user for the name of the file, then appends the .txt file type, decided to do this because every time I used it\n",
    "    #I'd forget to write.txt\n",
    "    file = str(input(\"Enter File Name: \")+'.txt')\n",
    "    time.sleep(0.25)\n",
    "    #Prints the file name being used in Bold for clarity on what file is being analyzed\n",
    "    print (\"File name is \"+ BOLD + str(file) + END )\n",
    "    time.sleep(0.25)\n",
    "    #Indicates to the user that the file is being \"cleaned\"\n",
    "    print('Cleaning Data...')\n",
    "    #calls readclean function to eliminate punctuation and convert text file to list\n",
    "    cleanfile = readclean(file)\n",
    "    time.sleep(0.25)\n",
    "    #indicates to user that the program is now \"processing\" the data\n",
    "    print ('Processing Data...')\n",
    "    #calls process function to count all of the different types of words included in the tweets\n",
    "    results = process(cleanfile)\n",
    "    time.sleep(0.25)\n",
    "    #indicates to the user that the program is now \"analyzing\" the results to answer the homework questions\n",
    "    print('Analyzing...')\n",
    "    time.sleep(0.5)\n",
    "    #calls the analyze function to review the results and answer the homework questions\n",
    "    analyze(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11110111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name: Biden\n",
      "File name is \u001b[1mBiden.txt\u001b[0m\n",
      "Cleaning Data...\n",
      "Processing Data...\n",
      "Analyzing...\n",
      "\u001b[1m\u001b[4mAnalysis Results:\u001b[0m\u001b[0m\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "the total word count is 47057\n",
      "the negative word count is 1716\n",
      "the positive word count is 1424\n",
      "the stop word count is 20789\n",
      "the other word count is 23128\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "the total word ratio is: 1.0:1\n",
      "the negative word ratio is: 0.04:1\n",
      "the positive word ratio is: 0.03:1\n",
      "the stop word ratio is: 0.44:1\n",
      "the other word ratio is: 0.49:1\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "the ratio of positive words to negative words is 0.83:1\n",
      "\u001b[1mQuestion 4:\u001b[0m\n",
      "the sentiment is weakly negative\n"
     ]
    }
   ],
   "source": [
    "HW1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef59fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name: Putin\n",
      "File name is \u001b[1mPutin.txt\u001b[0m\n",
      "Cleaning Data...\n",
      "Processing Data...\n",
      "Analyzing...\n",
      "\u001b[1m\u001b[4mAnalysis Results:\u001b[0m\u001b[0m\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "the total word count is 53583\n",
      "the negative word count is 2012\n",
      "the positive word count is 1633\n",
      "the stop word count is 24016\n",
      "the other word count is 25922\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "the total word ratio is: 1.0:1\n",
      "the negative word ratio is: 0.04:1\n",
      "the positive word ratio is: 0.03:1\n",
      "the stop word ratio is: 0.45:1\n",
      "the other word ratio is: 0.48:1\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "the ratio of positive words to negative words is 0.81:1\n",
      "\u001b[1mQuestion 4:\u001b[0m\n",
      "the sentiment is weakly negative\n"
     ]
    }
   ],
   "source": [
    "HW1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7416cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name: UN\n",
      "File name is \u001b[1mUN.txt\u001b[0m\n",
      "Cleaning Data...\n",
      "Processing Data...\n",
      "Analyzing...\n",
      "\u001b[1m\u001b[4mAnalysis Results:\u001b[0m\u001b[0m\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "the total word count is 76233\n",
      "the negative word count is 3165\n",
      "the positive word count is 1224\n",
      "the stop word count is 29947\n",
      "the other word count is 41897\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "the total word ratio is: 1.0:1\n",
      "the negative word ratio is: 0.04:1\n",
      "the positive word ratio is: 0.02:1\n",
      "the stop word ratio is: 0.39:1\n",
      "the other word ratio is: 0.55:1\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "the ratio of positive words to negative words is 0.39:1\n",
      "\u001b[1mQuestion 4:\u001b[0m\n",
      "the sentiment is strongly negative\n"
     ]
    }
   ],
   "source": [
    "HW1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ea9a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name: Trump_Raw_Tweets_Fall22\n",
      "File name is \u001b[1mTrump_Raw_Tweets_Fall22.txt\u001b[0m\n",
      "Cleaning Data...\n",
      "Processing Data...\n",
      "Analyzing...\n",
      "\u001b[1m\u001b[4mAnalysis Results:\u001b[0m\u001b[0m\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "the total word count is 54162\n",
      "the negative word count is 2113\n",
      "the positive word count is 1125\n",
      "the stop word count is 22874\n",
      "the other word count is 28050\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "the total word ratio is: 1.0:1\n",
      "the negative word ratio is: 0.04:1\n",
      "the positive word ratio is: 0.02:1\n",
      "the stop word ratio is: 0.42:1\n",
      "the other word ratio is: 0.52:1\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "the ratio of positive words to negative words is 0.53:1\n",
      "\u001b[1mQuestion 4:\u001b[0m\n",
      "the sentiment is strongly negative\n"
     ]
    }
   ],
   "source": [
    "HW1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057646a",
   "metadata": {},
   "source": [
    "Shortfalls/Observations:\n",
    "1. This only calculates the ratio of negative to positive words, doesn't account for the possibility of someone using alot of negative words in a single tweet, so it's really not a sentiment analysis per tweet, but per word.\n",
    "2. Does not screen for whether the negative or positive word was used to describe the person or organization analyzed, I can think of dozens of examples of tweets using the negative words but they don't actually have negative sentiment for the person or organization analyzed\n",
    "3. usernames may be a positive or negative word which may be adding positive/negative counts when it's really just someone's name. I included an if loop to eliminate trump from the positive word list when Trump is the subject of the analysis to try to account for this at least a little. \n",
    "4. my strong/weak sentiment ratios used for the calculation are just based on my intuition, not sure how to mathematically describe strong versus weak sentiment, just used 1.2 and 0.8 as the cut off"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
